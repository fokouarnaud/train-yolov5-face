#!/usr/bin/env python3
"""
Script d'entra√Ænement optimis√© pour ADYOLOv5-Face avec gestion m√©moire
R√©sout les probl√®mes CUDA Out of Memory
"""

import os
import sys
import subprocess
import torch
from config import MODEL_CONFIGS, DEFAULT_PATHS

def optimize_gpu_memory():
    """Optimise les param√®tres de m√©moire GPU"""
    print("üîß Optimisation de la m√©moire GPU...")
    
    # Variables d'environnement pour optimiser CUDA
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
    os.environ['CUDA_LAUNCH_BLOCKING'] = '0'
    
    # Nettoyer le cache CUDA
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print(f"   ‚úÖ GPU d√©tect√©: {torch.cuda.get_device_name()}")
        print(f"   üìä M√©moire libre: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        print("   ‚ùå Aucun GPU CUDA d√©tect√©")

def get_optimal_batch_size():
    """D√©termine le batch size optimal selon la m√©moire disponible"""
    if torch.cuda.is_available():
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # GB
        
        if total_memory > 35:  # A100/V100 40GB
            return 16  # Batch size r√©duit mais s√ªr
        elif total_memory > 15:  # T4 16GB
            return 8
        elif total_memory > 10:  # GTX 1080 Ti 11GB
            return 4
        else:  # GPU plus petit
            return 2
    else:
        return 4  # CPU fallback

def train_adyolov5_optimized():
    """Lance l'entra√Ænement ADYOLOv5 avec param√®tres optimis√©s"""
    
    optimize_gpu_memory()
    
    model_config = MODEL_CONFIGS['ad']
    yolo_face_path = DEFAULT_PATHS["yolo_dir"]
    optimal_batch_size = get_optimal_batch_size()
    
    print(f"üöÄ D√©marrage entra√Ænement ADYOLOv5-Face optimis√©")
    print(f"   üì¶ Batch size optimal: {optimal_batch_size}")
    print(f"   üñºÔ∏è  R√©solution: 512px (r√©duite pour √©conomiser m√©moire)")
    print(f"   üìÅ Mod√®le: {model_config['yaml']}")
    
    # Commande d'entra√Ænement optimis√©e
    train_cmd = [
        "python", f"{yolo_face_path}/train.py",
        "--data", f"{yolo_face_path}/data/widerface.yaml",
        "--cfg", f"{yolo_face_path}/models/{model_config['yaml']}",
        "--weights", f"{yolo_face_path}/weights/{model_config['weights']}",
        "--batch-size", str(optimal_batch_size),  # Batch size optimis√©
        "--epochs", "50",  # Moins d'epochs pour test initial
        "--img", "512",  # R√©solution r√©duite (au lieu de 640)
        "--hyp", f"{yolo_face_path}/data/hyp.adyolo.yaml",
        "--project", f"{yolo_face_path}/runs/train",
        "--name", "adyolov5_memory_optimized",
        "--exist-ok",
        "--cache",  # Cache les images pour acc√©l√©rer
        "--device", "0",  # Force GPU 0
        "--workers", "2",  # Moins de workers
        "--patience", "10"  # Early stopping
    ]
    
    print(f"üìã Commande: {' '.join(train_cmd)}")
    
    try:
        # Lancer l'entra√Ænement
        result = subprocess.run(train_cmd, cwd=yolo_face_path, capture_output=True, text=True)
        
        if result.returncode == 0:
            print("‚úÖ Entra√Ænement termin√© avec succ√®s!")
            print(f"üìÅ R√©sultats sauv√©s dans: {yolo_face_path}/runs/train/adyolov5_memory_optimized")
        else:
            print("‚ùå Erreur lors de l'entra√Ænement:")
            print(result.stderr)
            
            # Suggestions si √©chec
            print("\nüí° Suggestions en cas d'erreur m√©moire:")
            print("   1. R√©duire encore le batch-size (essayer --batch-size 2)")
            print("   2. R√©duire la r√©solution (essayer --img 416)")
            print("   3. Utiliser un mod√®le plus petit (yolov5n.pt au lieu de yolov5s.pt)")
            
    except Exception as e:
        print(f"‚ùå Erreur lors de l'ex√©cution: {e}")

def test_memory_simple():
    """Test simple pour v√©rifier si les modules GD fonctionnent sans erreur m√©moire"""
    print("üß™ Test des modules GD optimis√©s...")
    
    try:
        # Import et test des modules
        yolo_face_path = DEFAULT_PATHS["yolo_dir"]
        sys.path.append(yolo_face_path)
        from models.gd import GDFusion, AttentionFusion, TransformerFusion
        
        # Test avec tenseurs de petite taille
        test_tensor = torch.randn(1, 128, 32, 32)  # Batch=1, plus petit
        
        if torch.cuda.is_available():
            test_tensor = test_tensor.cuda()
        
        # Test AttentionFusion
        attn_fusion = AttentionFusion(128)
        if torch.cuda.is_available():
            attn_fusion = attn_fusion.cuda()
        
        output_attn = attn_fusion((test_tensor, test_tensor))
        print(f"   ‚úÖ AttentionFusion OK: {output_attn.shape}")
        
        # Test TransformerFusion  
        trans_fusion = TransformerFusion(128)
        if torch.cuda.is_available():
            trans_fusion = trans_fusion.cuda()
            
        output_trans = trans_fusion((test_tensor, test_tensor))
        print(f"   ‚úÖ TransformerFusion OK: {output_trans.shape}")
        
        # Test GDFusion
        gd_fusion = GDFusion(128, 128, 'attention')
        if torch.cuda.is_available():
            gd_fusion = gd_fusion.cuda()
            
        output_gd = gd_fusion(test_tensor)
        print(f"   ‚úÖ GDFusion OK: {output_gd.shape}")
        
        print("‚úÖ Tous les modules GD fonctionnent correctement!")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors du test: {e}")
        return False

if __name__ == "__main__":
    print("=" * 60)
    print("üéØ ADYOLOv5-Face - Entra√Ænement Optimis√© M√©moire")
    print("=" * 60)
    
    # Test des modules avant entra√Ænement
    if test_memory_simple():
        # Si les modules fonctionnent, lancer l'entra√Ænement
        train_adyolov5_optimized()
    else:
        print("‚ùå Les modules GD ont des erreurs, v√©rifiez l'impl√©mentation")
